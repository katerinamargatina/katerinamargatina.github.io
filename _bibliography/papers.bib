---
---

@string{aps = {American Physical Society,}}
%--------------------------------------------------------------------------
% 2024
%--------------------------------------------------------------------------
@misc{prism,
abbr={Arxiv},
    selected={true},
      title={The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models},
      author={Katerina Margatina and Timo Schick and Nikolaos Aletras and Jane Dwivedi-Yu},
      year={2024},
      arxiv={2404.16019},
      abstract={Human feedback plays a central role in the alignment of Large Language Models (LLMs). However, open questions remain about the methods (how), domains (where), people (who) and objectives (to what end) of human feedback collection. To navigate these questions, we introduce PRISM, a new dataset which maps the sociodemographics and stated preferences of 1,500 diverse participants from 75 countries, to their contextual preferences and fine-grained feedback in 8,011 live conversations with 21 LLMs. PRISM contributes (i) wide geographic and demographic participation in human feedback data; (ii) two census-representative samples for understanding collective welfare (UK and US); and (iii) individualised feedback where every rating is linked to a detailed participant profile, thus permitting exploration of personalisation and attribution of sample artefacts. We focus on collecting conversations that centre subjective and multicultural perspectives on value-laden and controversial topics, where we expect the most interpersonal and cross-cultural disagreement. We demonstrate the usefulness of PRISM via three case studies of dialogue diversity, preference diversity, and welfare outcomes, showing that it matters which humans set alignment norms. As well as offering a rich community resource, we advocate for broader participation in AI development and a more inclusive approach to technology design.},
      tldr={https://x.com/hannahrosekirk/status/1783470502595440884},
      blog={https://mlcommons.org/2024/05/prism/}
}
%--------------------------------------------------------------------------
% 2023
%--------------------------------------------------------------------------
@misc{margatina2023active,
abbr={EMNLP-Findings},
    selected={true},
      title={Active Learning Principles for In-Context Learning with Large Language Models},
      author={Katerina Margatina and Timo Schick and Nikolaos Aletras and Jane Dwivedi-Yu},
      year={2023},
      arxiv={2305.14264},
      abstract={The remarkable advancements in large language models (LLMs) have significantly enhanced the performance in few-shot learning settings. By using only a small number of labeled examples, referred to as demonstrations, LLMs can effectively grasp the task at hand through in-context learning. However, the process of selecting appropriate demonstrations has received limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based Active Learning (AL) problem over a single iteration. Our objective is to investigate how AL algorithms can serve as effective demonstration selection methods for in-context learning. We compare various standard AL algorithms based on uncertainty, diversity, and similarity, and consistently observe that the latter outperforms all other methods, including random sampling. Notably, uncertainty sampling, despite its success in conventional supervised learning scenarios, performs poorly in this context. Our extensive experimentation involving a diverse range of GPT and OPT models across 24 classification and multi-choice tasks, coupled with thorough analysis, unambiguously demonstrates that in-context example selection through AL prioritizes high-quality examples that exhibit low uncertainty and bear similarity to the test examples.},
      tldr={https://twitter.com/katemargatina/status/1661321935127556097},
}

@misc{ahmed2023,
abbr={EMNLP},
      title={Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?},
      author={Ahmed Alajrami and Katerina Margatina and Nikolaos Aletras},
      year={2023},
      arxiv={2310.17271},
      abstract={Understanding how and what pre-trained language models (PLMs) learn about language is an open challenge in natural language processing. Previous work has focused on identifying whether they capture semantic and syntactic information, and how the data or the pre-training objective affects their performance. However, to the best of our knowledge, no previous work has specifically examined how information loss in input token characters affects the performance of PLMs. In this study, we address this gap by pre-training language models using small subsets of characters from individual tokens. Surprisingly, we find that pre-training even under extreme settings, i.e. using only one character of each token, the performance retention in standard NLU benchmarks and probing tasks compared to full-token models is high. For instance, a model pre-trained only on single first characters from tokens achieves performance retention of approximately 90\% and 77\% of the full-token model in SuperGLUE and GLUE tasks, respectively.},
      tldr={https://twitter.com/nikaletras/status/1717915350799437865},
}

@inproceedings{margatina2023limitations,
abbr={ACL-Findings},
    selected={true},
        arxiv={2305.13342},
      title={On the Limitations of Simulating Active Learning},
      author={Katerina Margatina and Nikolaos Aletras},
      year={2023},
      html={https://aclanthology.org/2023.findings-acl.269/},
      pdf={https://aclanthology.org/2023.findings-acl.269.pdf},
      booktitle={Findings of the Association for Computational Linguistics (ACL)},
      abstract={Active learning (AL) is a human-and-model-in-the-loop paradigm that iteratively selects informative unlabeled data for human annotation, aiming to improve over random sampling. However, performing AL experiments with human annotations on-the-fly is a laborious and expensive process, thus unrealistic for academic research. An easy fix to this impediment is to simulate AL, by treating an already labeled and publicly available dataset as the pool of unlabeled data. In this position paper, we first survey recent literature and highlight the challenges across all different steps within the AL loop. We further unveil neglected caveats in the experimental setup that can significantly affect the quality of AL research. We continue with an exploration of how the simulation setting can govern empirical findings, arguing that it might be one of the answers behind the ever posed question ``why do active learning algorithms sometimes fail to outperform random sampling?''. We argue that evaluating AL algorithms on available labeled datasets might provide a lower bound as to their effectiveness in real data. We believe it is essential to collectively shape the best practices for AL research, particularly as engineering advancements in LLMs push the research focus towards data-driven approaches (e.g., data efficiency, alignment, fairness). In light of this, we have developed guidelines for future work. Our aim is to draw attention to these limitations within the community, in the hope of finding ways to address them.},
}

@inproceedings{dynamic_templama,
abbr={EACL},
    title = "Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views",
      author = {Katerina Margatina  and
      Shuai Wang  and
      Yogarshi Vyas  and
      Neha Anna John  and
      Yassine Benajiba and
      Miguel Ballesteros},
      booktitle = "Proceedings of the European Meeting of the Association for Computational Linguistics (EACL)",
    selected={true},
    year = "2023",
    arxiv={2302.12297},
    code={https://github.com/amazon-science/temporal-robustness},
    tldr={https://twitter.com/katemargatina/status/1653535912532344833},
    poster={https://drive.google.com/file/d/1k_AxteMtoFfXt-ReX1VYxz1tME8InEW_/view?usp=share_link},
    html={https://aclanthology.org/2023.eacl-main.211/},
    slides={https://drive.google.com/file/d/1Ln29c02nd2iGMv7diajdacDs5OXNxMyl/view?usp=sharing},
    pdf={https://aclanthology.org/2023.eacl-main.211.pdf},
    blog={https://www.amazon.science/publications/dynamic-benchmarking-of-masked-language-models-on-temporal-concept-drift-with-multiple-views},
    abstract={Temporal concept drift refers to the problem of data changing over time. In the field of NLP, that would entail that language (e.g. new expressions, meaning shifts) and factual knowledge (e.g. new concepts, updated facts) evolve over time. Focusing on the latter, we benchmark 11 pretrained masked language models (MLMs) on a series of tests designed to evaluate the effect of temporal concept drift, as it is crucial that widely used language models remain up-to-date with the ever-evolving factual updates of the real world. Specifically, we provide a holistic framework that (1) dynamically creates temporal test sets of any time granularity (e.g. month, quarter, year) of factual data from Wikidata, (2) constructs fine-grained splits of tests (e.g. updated, new, unchanged facts) to ensure comprehensive analysis, and (3) evaluates MLMs in three distinct ways (single-token probing, multi-token generation, MLM scoring). In contrast to prior work, our framework aims to unveil how robust an MLM is over time and thus to provide a signal in case it has become outdated, by leveraging multiple views of evaluation.}
}

@inproceedings{al_nli,
abbr={EACL},
    title = "Investigating Multi-source Active Learning for Natural Language Inference",
      author = {Ard Snijders  and
      Douwe Kiela  and
      Katerina Margatina},
      booktitle = "Proceedings of the European Meeting of the Association for Computational Linguistics (EACL)",
    selected={true},
    year = "2023",
    arxiv={2302.06976},
    code={https://github.com/asnijders/multi_source_AL},
    tldr={https://twitter.com/katemargatina/status/1628714831409778688},
    poster={https://drive.google.com/file/d/1_a6N6l-KYcpAGEUuEVgjXdXJ8SCdpK3c/view?usp=share_link},
    html={https://aclanthology.org/2023.eacl-main.160/},
    pdf={https://aclanthology.org/2023.eacl-main.160.pdf},
    abstract={In recent years, active learning has been successfully applied to an array of NLP tasks. However, prior work often assumes that training and test data are drawn from the same distribution. This is problematic, as in real-life settings data may stem from several sources of varying relevance and quality. We show that four popular active learning schemes fail to outperform random selection when applied to unlabelled pools comprised of multiple data sources on the task of natural language inference. We reveal that uncertainty-based strategies perform poorly due to the acquisition of collective outliers, i.e., hard-to-learn instances that hamper learning and generalisation. When outliers are removed, strategies are found to recover and outperform random baselines. In further analysis, we find that collective outliers vary in form between sources, and show that hard-to-learn data is not always categorically harmful. Lastly, we leverage dataset cartography to introduce difficulty-stratified testing and find that different strategies are affected differently by example learnability and difficulty.}
}
%--------------------------------------------------------------------------
% 2022
%--------------------------------------------------------------------------
@proceedings{dadc-2022-dynamic,
abbr={DADC@NAACL},
    title = "Proceedings of the First Workshop on Dynamic Adversarial Data Collection",
    editor = "Bartolo, Max  and
      Kirk, Hannah  and
      Rodriguez, Pedro  and
      Margatina, Katerina  and
      Thrush, Tristan  and
      Jia, Robin  and
      Stenetorp, Pontus  and
      Williams, Adina  and
      Kiela, Douwe",
      author = {Max Bartolo  and
      Hannah Kirk  and
      Pedro Rodriguez  and
      Katerina Margatina  and
      Tristan Thrush  and
      Robin Jia  and
      Pontus Stenetorp  and
      Adina Williams  and
      Douwe Kiela},
    month = jul,
    year = "2022",
    address = "Seattle, WA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.dadc-1.0",
    html = "https://dadcworkshop.github.io/",
    pdf = "https://aclanthology.org/2022.dadc-1.0",
}

@inproceedings{ex-balm,
abbr={ACL},
      title={On the Importance of Effectively Adapting Pretrained Language Models for Active Learning},
      author={Katerina Margatina
       and Lo√Øc Barrault and Nikolaos Aletras},
      year={2022},
      booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
      selected={true},
      code={https://github.com/mourga/contrastive-active-learning},
      arxiv={2104.08320},
      slides={https://drive.google.com/file/d/1Gn-a0s2sA2duH5PyFi-JS6MM3EqkM69O/view?usp=sharing},
      poster={https://drive.google.com/file/d/1z6jJsZOb8uYbqZWFsyQHlXOisBkruN_t/view?usp=sharing},
      tldr={https://twitter.com/katemargatina/status/1508445688333582341},
      html = "https://aclanthology.org/2022.acl-short.93/",
      pdf = "https://aclanthology.org/2022.acl-short.93.pdf",
      abstract={Recent Active Learning (AL) approaches in Natural Language Processing (NLP) proposed using off-the-shelf pretrained language models (LMs). In this paper, we argue that these LMs are not adapted effectively to the downstream task during AL and we explore ways to address this issue. We suggest to first adapt the pretrained LM to the target task by continuing training with all the available unlabeled data and then use it for AL. We also propose a simple yet effective fine-tuning method to ensure that the adapted LM is properly trained in both low and high resource scenarios during AL. Our experiments demonstrate that our approach provides substantial data efficiency improvements compared to the standard fine-tuning approach, suggesting that a poor training strategy can be catastrophic for AL.}
}

@inproceedings{xcultural,
abbr={ACL},
award={üåç Theme üåé},
      title={Challenges and Strategies in Cross-Cultural NLP},
      author={Daniel Hershcovich and Stella Frank and Heather Lent and Miryam de Lhoneux and Mostafa Abdou and Stephanie Brandl and Emanuele Bugliarello and Laura Cabello Piqueras and Ilias Chalkidis and Ruixiang Cui and Constanza Fierro and Katerina Margatina and Phillip Rust and Anders S√∏gaard},
      year={2022},
      booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
      pdf = "https://danielhers.github.io/xculture.pdf",
      arxiv = {2203.10020},
      tldr = {https://twitter.com/daniel_hers/status/1505829084210868224},
      html = "https://aclanthology.org/2022.acl-long.482/",
      pdf = "https://aclanthology.org/2022.acl-long.482.pdf",
      abstract = "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies."
}
%--------------------------------------------------------------------------
% 2021
%--------------------------------------------------------------------------
@inproceedings{cal,
abbr={EMNLP},
award={‚ú® Oral ‚ú®},
      title={Active Learning by Acquiring Contrastive Examples},
      author={Katerina Margatina and Giorgos Vernikos
       and Lo√Øc Barrault and Nikolaos Aletras},
      year={2021},
      booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      selected={true},
      code={https://github.com/mourga/contrastive-active-learning},
      arxiv={2109.03764},
      html = "https://aclanthology.org/2021.emnlp-main.51/",
      pdf = "https://aclanthology.org/2021.emnlp-main.51.pdf",
      pages = "650--663",
      tldr={https://twitter.com/katemargatina/status/1437393852227276801?s=20},
      slides = {https://drive.google.com/file/d/1bWx9QPRTFjf49XLgCdV34w3w1SXETylv/view?usp=sharing},
      poster = {https://drive.google.com/file/d/1JAdukTFb0ceAR0WRk9zEW2GqLiTG_p7H/view?usp=sharing},
      abstract={Common acquisition functions for active learning use either uncertainty or diversity sampling, aiming to select difficult and diverse data points from the pool of unlabeled data, respectively. In this work, leveraging the best of both worlds, we propose an acquisition function that opts for selecting \textit{contrastive examples}, i.e. data points that are similar in the model feature space and yet the model outputs maximally different predictive likelihoods. We compare our approach, CAL (Contrastive Active Learning), with a diverse set of acquisition functions in four natural language understanding tasks and seven datasets. Our experiments show that CAL performs consistently better or equal than the best performing baseline across all tasks, on both in-domain and out-of-domain data. We also conduct an extensive ablation study of our method and we further analyze all actively acquired datasets showing that CAL achieves a better trade-off between uncertainty and diversity compared to other strategies.}
}
@inproceedings{frustratingly,
abbr={EMNLP},
      title={Frustratingly Simple Alternatives to Masked Language Modeling},
      author={Atsuki Yamaguchi and George Chrysostomou and Katerina Margatina and Nikolaos Aletras},
      year={2021},
      booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      code={https://github.com/gucci-j/light-transformer-emnlp2021},
      arxiv={2109.01819},
      html = "https://aclanthology.org/2021.emnlp-main.249/",
      pages = "3116--3125",
      pdf = "https://aclanthology.org/2021.emnlp-main.249.pdf",
      pages = "650--663",
      tldr={https://twitter.com/nikaletras/status/1435206594623574019?s=20},
      abstract={Masked language modeling (MLM), a self-supervised pretraining objective, is widely used in natural language processing for learning text representations. MLM trains a model to predict a random sample of input tokens that have been replaced by a [MASK] placeholder in a multi-class setting over the entire vocabulary. When pretraining, it is common to use alongside MLM other auxiliary objectives on the token or sequence level to improve downstream performance (e.g. next sentence prediction). However, no previous work so far has attempted in examining whether other simpler linguistically intuitive or not objectives can be used standalone as main pretraining objectives. In this paper, we explore five simple pretraining objectives based on token-level classification tasks as replacements of MLM. Empirical results on GLUE and SQuAD show that our proposed methods achieve comparable or better performance to MLM using a BERT-BASE architecture. We further validate our methods using smaller models, showing that pretraining a model with 41% of the BERT-BASE's parameters, BERT-MEDIUM results in only a 1% drop in GLUE scores with our best objective.}
}

%--------------------------------------------------------------------------
% 2020
%--------------------------------------------------------------------------
@inproceedings{vernikos-etal-2020-domain,
    abbr = {EMNLP-Findings},
    title = "{D}omain {A}dversarial {F}ine-{T}uning as an {E}ffective {R}egularizer",
    author = "Giorgos Vernikos, and
      Katerina Margatina, and
      Alexandra Chronopoulou,  and
      Ion Androutsopoulos",
    booktitle = "Findings of the Association for Computational Linguistics (EMNLP)",
    year = "2020",
    html = "https://www.aclweb.org/anthology/2020.findings-emnlp.278",
    pdf = "https://aclanthology.org/2020.findings-emnlp.278.pdf",
    pages = "3103--3112",
    code = {https://github.com/GeorgeVern/AFTERV1.0},
    abstract = "In Natural Language Processing (NLP), pretrained language models (LMs) that are transferred to downstream tasks have been recently shown to achieve state-of-the-art results. However, standard fine-tuning can degrade the general-domain representations captured during pretraining. To address this issue, we introduce a new regularization technique, AFTER; domain Adversarial Fine-Tuning as an Effective Regularizer. Specifically, we complement the task-specific loss used during fine-tuning with an adversarial objective. This additional loss term is related to an adversarial classifier, that aims to discriminate between in-domain and out-of-domain text representations. Indomain refers to the labeled dataset of the task at hand while out-of-domain refers to unlabeled data from a different domain. Intuitively, the adversarial classifier acts as a regularize which prevents the model from overfitting to the task-specific domain. Empirical results on various natural language understanding tasks show that AFTER leads to improved performance compared to standard fine-tuning.",
    tldr= "https://twitter.com/gvernikos/status/1311010294735482880?s=20"
}

%--------------------------------------------------------------------------
% 2019
%--------------------------------------------------------------------------
@article{thesis,
  abbr = {Thesis},
  author = 	"Margatina, Katerina",
  title = 	{Transfer Learning and Attention-based Conditioning Methods for Natural Language Processing},
  journaltitle = 	"Thesis, NTUA",
  year = 	"2019",
  date={2019},
  pdf = 	"http://artemis.cslab.ece.ntua.gr:8080/jspui/bitstream/123456789/17295/1/Eng_Thesis_Kate.pdf",
  slides = {https://drive.google.com/open?id=1CkV6TfdObiQfozh7a4dH_pmJFgxvr2BH}
}

@inproceedings{margatina-etal-2019-attention,
    abbr = {ACL},
    title = "Attention-based Conditioning Methods for External Knowledge Integration",
    author = "Katerina Margatina,  and
      Christos Baziotis,  and
      Alexandros Potamianos",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2019",
    address = "Florence, Italy",
    html = {https://www.aclweb.org/anthology/P19-1385},
    pdf = "https://aclanthology.org/P19-1385.pdf",
    pages = "3944--3951",
    code = {https://github.com/mourga/affective-attention},
    poster = {https://drive.google.com/file/d/1Z0xZ_y_oJKpeeXZ_8z2-sOQJZIQdkagZ/view},
    abstract = "In this paper, we present a novel approach for incorporating external knowledge in Recurrent Neural Networks (RNNs). We propose the integration of lexicon features into the self-attention mechanism of RNN-based architectures. This form of conditioning on the attention distribution, enforces the contribution of the most salient words for the task at hand. We introduce three methods, namely attentional concatenation, feature-based gating and affine transformation. Experiments on six benchmark datasets show the effectiveness of our methods. Attentional feature-based gating yields consistent performance improvement across tasks. Our approach is implemented as a simple add-on module for RNN-based models with minimal computational overhead and can be adapted to any deep neural architecture.",
}



%--------------------------------------------------------------------------
% 2018
%--------------------------------------------------------------------------
@inproceedings{W18-6209,
  abbr = {WASSA@EMNLP},
  author = 	"Alexandra* Chronopoulou,
		and Katerina* Margatina,
		and Christos Baziotis,
		and Alexandros Potamianos",
  title = 	"NTUA-SLP at IEST 2018: Ensemble of Neural Transfer Methods for Implicit Emotion Classification",
  booktitle = 	"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA)",
  year = 	"2018",
  pdf = 	"https://aclanthology.org/W18-6209.pdf",
  html = 	"http://aclweb.org/anthology/W18-6209",
  code={https://github.com/alexandra-chron/ntua-slp-wassa-iest2018},
  slides={https://drive.google.com/file/d/1hyUx69rVEzyFuBeZPtVWz8_JSb83d7jJ/view},
  abstract = {In this paper we present our approach to tackle the Implicit Emotion Shared Task (IEST) organized as part of WASSA 2018 at EMNLP 2018. Given a tweet, from which a certain word has been removed, we are asked to predict the emotion of the missing word. In this work, we experiment with neural Transfer Learning (TL) methods. Our models are based on LSTM networks, augmented with a self-attention mechanism. We use the weights of various pretrained models, for initializing specific layers of our networks. We leverage a big collection of unlabeled Twitter messages, for pretraining word2vec word embeddings and a set of diverse language models. Moreover, we utilize a sentiment analysis dataset for pretraining a model, which encodes emotion related information. The submitted model consists of an ensemble of the aforementioned TL models. Our team ranked 3rd out of 30 participants, achieving an F1 score of 0.703.},
}

