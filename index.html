<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  katerina margatina


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü¶ã</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-XXXXXXXXX');
</script>



<!-- Panelbear Analytics - We respect your privacy -->
<script async src="https://cdn.panelbear.com/analytics.js?site=XXXXXXXXX"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: 'XXXXXXXXX' });
</script>


    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/vitae/">
                vitae
                
              </a>
          </li>
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Katerina</span>   Margatina
    </h1>
  </header>

  <p></p>


  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/IMG_9500.JPG">
      
      
      <div class="contact-list">
        <span class="text-left">
  <a href="mailto:%6B%61%74%65%72%69%6E%61.%6D%61%72%67%61%74%69%6E%61@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a> Email
  
  <br><a href="https://scholar.google.com/citations?user=517t5gEAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a> Google Scholar
  <br><a href="https://www.semanticscholar.org/author/Katerina-Margatina/82259306" target="_blank" title="Semantic Scholar"><i class="ai ai-semantic-scholar"></i></a> Semantic Scholar
  
  
  <br><a href="https://github.com/mourga" target="_blank" title="GitHub"><i class="fab fa-github"></i></a> GitHub
  <br><a href="https://www.linkedin.com/in/katerina-margatina" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a> LinkedIn
  <br><a href="https://twitter.com/katemargatina" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a> Twitter
  
  
  
  
</span>
        <div class="contact-note"></div>
      </div>
    </div>
    

    <div class="clearfix" style="text-align: justify">
      <p>I‚Äôm an Applied Scientist at Amazon in NYC, working with the AWS AI Fundamental Research team on Agentic AI. My main focus is on improving how LLM agents work‚Äîmaking them more useful, reliable, and efficient. Previous projects include <a href="https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-announces-general-availability-of-multi-agent-collaboration/">multi-agents collaboration</a>, <a href="https://aws.amazon.com/blogs/aws/agents-for-amazon-bedrock-now-support-memory-retention-and-code-interpretation-preview/">long-term memory</a> and evaluation in Amazon Bedrock Agents. Currently I am working on the <a href="https://aws.amazon.com/security-agent/">AWS Security Agent</a>, addressing several challenges to ensure that the agent does thorough automated penetration testing in web apps and provides reliable vulnerability findings.</p>

<p>I earned my PhD in Computer Science at the University Sheffield, under the supervision of <a href="http://nikosaletras.com/">Prof. Nikos Aletras</a>. I researched <a href="https://etheses.whiterose.ac.uk/id/eprint/35849/">active learning algorithms for data efficient LLMs</a>.
Along the way, I spent time as a Research Scientist intern at Meta AI (FAIR) in London where I explored the intersection of <a href="https://aclanthology.org/2023.findings-emnlp.334/">in-context and active learning methods for LLMs</a>, and at AWS in NYC where I studied <a href="https://aclanthology.org/2023.eacl-main.211/">temporal robustness of LLMs</a>.
I also visited the <a href="https://coastalcph.github.io/">CoAStaL</a> group at the University of Copenhagen, where I worked on learning from disagreement and <a href="https://aclanthology.org/2022.acl-long.482/">cross-cultural NLP</a>.</p>

<p>Before my doctoral studies (i.e., what feels like a lifetime ago), I was a Machine Learning Engineer at <a href="https://www.deepsea.ai/">DeepSea Technologies</a>. 
In my undergrad, I studied <a href="https://www.ece.ntua.gr/en">Electrical &amp; Computer Engineering</a> at the National Technical University of Athens (NTUA).</p>


    </div>

    <p></p>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Dec 2, 2025</th>
          <td>
            
              Thrilled to have <a href="https://aws.amazon.com/security-agent/">AWS Security Agent</a> launched in Preview at Re:Invent! Super excited to share our work! Check the announcement <a href="https://aws.amazon.com/blogs/aws/new-aws-security-agent-secures-applications-proactively-from-design-to-deployment-preview/">here</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 2, 2025</th>
          <td>
            
              Very excited to have our paper <a href="https://arxiv.org/abs/2506.01859">CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions</a> accepted at ACL 2025 (main)!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 13, 2024</th>
          <td>
            
              üåàPRISM won best <a href="https://blog.neurips.cc/2024/12/10/announcing-the-neurips-2024-best-paper-awards/">paper award at NeurIPS 2024 Datasets &amp; Benchmarks track</a>!!üöÄüöÄüöÄ

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 3, 2024</th>
          <td>
            
              My PhD thesis <a href="https://etheses.whiterose.ac.uk/35849/">Exploring Active Learning Algorithms for Data Efficient Language Models</a> is finally online!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 22, 2024</th>
          <td>
            
              I just defended my PhD and got it with no corrections!!!ü•∞üéì

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 24, 2024</th>
          <td>
            
              Super excited to share that our preprint <a href="https://arxiv.org/abs/2404.16019">The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models</a> is on Arxiv!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 16, 2024</th>
          <td>
            
              Life update! I joined AWS Bedrock as an Applied Scientist working in LLM Agents.ü§ñ

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    <p></p>

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
    <div class="col-sm-2 abbr">
        
        
        <abbr class="badge">ACL</abbr>
        
        

        
<!--        -->

        
    </div>

    <div id="confetti" class="col-sm-8">
        
        <div class="title">CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions</div>
        <div class="author">
            
            
            
            
            
            Tamer Alkhouli,
            
            
            
            
            
            
            
            
            <em>Katerina Margatina</em>,
            
            
            
            
            
            
            
            
            James Gung,
            
            
            
            
            
            
            
            
            
            Raphael Shu,
            
            
            
            
            
            
            
            
            
            Claudia Zaghi,
            
            
            
            
            
            
            
            
            
            Monica Sunkara,
            
            
            
            
            
            
            
            
            
            and Yi Zhang
            
            
            
            
            
        </div>

        <div class="periodical">
            
            <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics.</em>
            
            
            2025
            
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            
            
            <a href="http://arxiv.org/abs/2506.01859" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
            
            
            
            
            <a href="https://aclanthology.org/2025.acl-long.394.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
            
            
            
            
            <a href="https://www.amazon.science/publications/confetti-conversational-function-calling-evaluation-through-turn-level-interactions" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>We introduce Conversational Function-Calling Evaluation Through Turn-Level Interactions (CONFETTI), a conversational benchmark1 designed to evaluate the function-calling capabilities and response quality of large language models (LLMs). Current benchmarks lack comprehensive assessment of LLMs in complex conversational scenarios. CONFETTI addresses this gap through 109 human-simulated conversations, comprising 313 user turns and covering 86 APIs. These conversations explicitly target various conversational complexities, such as follow-ups, goal correction and switching, ambiguous and implicit goals. We perform off-policy turn-level evaluation using this benchmark targeting function-calling. Our benchmark also incorporates dialog act annotations to assess agent responses. We evaluate a series of state-of-the-art LLMs and analyze their performance with respect to the number of available APIs, conversation lengths, and chained function calling. Our results reveal that while some models are able to handle long conversations, and leverage more than 20+ APIs successfully, other models struggle with longer context or when increasing the number of APIs. We also report that the performance on chained function-calls is severely limited across the models. Overall, the top performing models on CONFETTI are Nova Pro (40.01%), Claude Sonnet v3.5 (35.46%) and Llama 3.1 405B (33.19%) followed by command-r-plus (31.18%) and Mistral-Large-2407 (30.07%).</p>
        </div>
        
    </div>
</div></li>
<li><div class="row">
    <div class="col-sm-2 abbr">
        
        
        <abbr class="badge">REALM</abbr>
        
        

        
<!--        -->

        
    </div>

    <div id="search" class="col-sm-8">
        
        <div class="title">A Study on Leveraging Search and Self-Feedback for Agent Reasoning</div>
        <div class="author">
            
            
            
            
            
            Karthikeyan K,
            
            
            
            
            
            
            
            
            
            Michelle Yuan,
            
            
            
            
            
            
            
            
            
            Elman Mansimov,
            
            
            
            
            
            
            
            
            <em>Katerina Margatina</em>,
            
            
            
            
            
            
            
            
            Anurag Pratik,
            
            
            
            
            
            
            
            
            
            Daniele Bonadiman,
            
            
            
            
            
            
            
            
            
            Monica Sunkara,
            
            
            
            
            
            
            
            
            
            Yi Zhang,
            
            
            
            
            
            
            
            
            
            and Yassine Benajiba
            
            
            
            
            
        </div>

        <div class="periodical">
            
            <em>In Proceedings of the 1st Workshop for Research on Agent Language Models (REALM 2025).</em>
            
            
            2025
            
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            
            
            <a href="http://arxiv.org/abs/2502.12094" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
            
            
            
            
            <a href="https://aclanthology.org/2025.realm-1.18.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Recent works have demonstrated that incorporating search during inference can significantly improve reasoning capabilities of language agents. Some approaches may make use of the ground truth or rely on model‚Äôs own generated feedback. The search algorithm uses this feedback to then produce values that will update its criterion for exploring and exploiting various reasoning paths. In this study, we investigate how search and model‚Äôs self-feedback can be leveraged for reasoning tasks. First, we explore differences in ground-truth feedback and self-feedback during search for math reasoning. Second, we observe limitations in applying search techniques to more complex tasks like tool-calling and design domain-specific approaches to address these gaps. Our experiments reveal challenges related to generalization when solely relying on self-feedback during search. For search to work effectively, either access to the ground-truth is needed or feedback mechanisms need to be carefully designed for the specific task.</p>
        </div>
        
    </div>
</div></li>
<li><div class="row">
    <div class="col-sm-2 abbr">
        
        
        <abbr class="badge">Thesis</abbr>
        
        

        
<!--        -->

        
    </div>

    <div id="thesis" class="col-sm-8">
        
        <div class="title">Exploring Active Learning Algorithms for Data Efficient Language Models</div>
        <div class="author">
            
            
            
            <em>Katerina Margatina</em>
            
            
            
        </div>

        <div class="periodical">
            
            
            2024
            
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            
            
            
            <a href="https://etheses.whiterose.ac.uk/35849/" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-pager"></i> HTML</a>
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Supervised learning is based in the premise that models can effectively solve tasks by learning from numerous examples, mapping inputs to outputs through iterative learning. However, contemporary deep learning models often require vast amounts of labeled data, termed training examples, for optimal performance. Unfortunately, not all training examples contribute equally to the learning process, leading to inefficiencies and resource wastage. Active Learning (AL) has emerged as a powerful paradigm for training language models in a data-efficient manner. By iteratively selecting informative unlabeled data points, which are then annotated by humans to form the training set, AL intelligently guides the training process, optimizing data selection for model improvement over random sampling. This thesis investigates various aspects of active learning algorithms for language mod- els, focusing on model training, data selection, in-context learning and simulation. The thesis is structured along four key publications that tackle these topics respectively. The first publication addresses the effective adaptation of pretrained language models for AL, highlighting the importance of task-specific fine-tuning. The second publication introduces a novel acquisition function, Contrastive Active Learning (CAL), which selects contrastive examples to improve AL performance. The third publication explores active learning principles for in-context learning with large language models, emphasizing the selection of informative demonstrations for few-shot learning. Lastly, the fourth publication critically examines the limitations of simulating AL experiments and pro- poses guidelines for future research. Through these contributions, this thesis aims to advance our understanding of AL algorithms for data-efficient language model training.</p>
        </div>
        
    </div>
</div></li>
<li><div class="row">
    <div class="col-sm-2 abbr">
        
        
        <abbr class="badge">NeurIPS</abbr>
        
        

        
        <p>
            <i class="em em-trophy" aria-role="presentation" style="font-size: 0.5em;" aria-label="TROPHY"></i>
            <span  style="font-size: 0.8em;" > üèÜ Best Paper</span>
        </p>
        
<!--        -->
<!--        <p>-->
<!--            <i class="em em-trophy" aria-role="presentation" style="font-size: 0.7em;" aria-label="TROPHY"></i>-->
<!--            <span  style="font-size: 0.8em;" > üèÜ Best Paper</span>-->
<!--        </p>-->
<!--        -->

        
    </div>

    <div id="prism" class="col-sm-8">
        
        <div class="title">The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models</div>
        <div class="author">
            
            
            
            
            
            Hannah Rose Kirk,
            
            
            
            
            
            
            
            
            
            Alexander Whitefield,
            
            
            
            
            
            
            
            
            
            Paul R√∂ttger,
            
            
            
            
            
            
            
            
            
            Andrew Bean,
            
            
            
            
            
            
            
            
            <em>Katerina Margatina</em>,
            
            
            
            
            
            
            
            
            Juan Ciro,
            
            
            
            
            
            
            
            
            
            Rafael Mosquera,
            
            
            
            
            
            
            
            
            
            Max Bartolo,
            
            
            
            
            
            
            
            
            
            Adina Williams,
            
            
            
            
            
            
            
            
            
            Bertie Vidgen He He,
            
            
            
            
            
            
            
            
            
            and Scott A. Hale
            
            
            
            
            
        </div>

        <div class="periodical">
            
            <em>In Proceedings of the Conference on Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks.</em>
            
            
            2024
            
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            
            
            <a href="http://arxiv.org/abs/2404.16019" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
            
            
            <a href="https://openreview.net/forum?id=DFr5hteojx#discussion" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-pager"></i> HTML</a>
            
            
            
            
            <a href="https://mlcommons.org/2024/05/prism/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
            
            
            <a href="https://x.com/hannahrosekirk/status/1783470502595440884" class="btn btn-sm z-depth-0" role="button" target="_blank">TL;DR</a>
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Human feedback plays a central role in the alignment of Large Language Models (LLMs). However, open questions remain about the methods (how), domains (where), people (who) and objectives (to what end) of human feedback collection. To navigate these questions, we introduce PRISM, a new dataset which maps the sociodemographics and stated preferences of 1,500 diverse participants from 75 countries, to their contextual preferences and fine-grained feedback in 8,011 live conversations with 21 LLMs. PRISM contributes (i) wide geographic and demographic participation in human feedback data; (ii) two census-representative samples for understanding collective welfare (UK and US); and (iii) individualised feedback where every rating is linked to a detailed participant profile, thus permitting exploration of personalisation and attribution of sample artefacts. We focus on collecting conversations that centre subjective and multicultural perspectives on value-laden and controversial topics, where we expect the most interpersonal and cross-cultural disagreement. We demonstrate the usefulness of PRISM via three case studies of dialogue diversity, preference diversity, and welfare outcomes, showing that it matters which humans set alignment norms. As well as offering a rich community resource, we advocate for broader participation in AI development and a more inclusive approach to technology design.</p>
        </div>
        
    </div>
</div></li>
<li><div class="row">
    <div class="col-sm-2 abbr">
        
        
        <abbr class="badge">EMNLP-Findings</abbr>
        
        

        
<!--        -->

        
    </div>

    <div id="margatina2023active" class="col-sm-8">
        
        <div class="title">Active Learning Principles for In-Context Learning with Large Language Models</div>
        <div class="author">
            
            
            
            
            <em>Katerina Margatina</em>,
            
            
            
            
            
            
            
            
            Timo Schick,
            
            
            
            
            
            
            
            
            
            Nikolaos Aletras,
            
            
            
            
            
            
            
            
            
            and Jane Dwivedi-Yu
            
            
            
            
            
        </div>

        <div class="periodical">
            
            <em>In Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) 2023</em>
            
            
            2023
            
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            
            
            <a href="http://arxiv.org/abs/2305.14264" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
            
            
            
            
            
            
            <a href="https://twitter.com/katemargatina/status/1661321935127556097" class="btn btn-sm z-depth-0" role="button" target="_blank">TL;DR</a>
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>The remarkable advancements in large language models (LLMs) have significantly enhanced the performance in few-shot learning settings. By using only a small number of labeled examples, referred to as demonstrations, LLMs can effectively grasp the task at hand through in-context learning. However, the process of selecting appropriate demonstrations has received limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based Active Learning (AL) problem over a single iteration. Our objective is to investigate how AL algorithms can serve as effective demonstration selection methods for in-context learning. We compare various standard AL algorithms based on uncertainty, diversity, and similarity, and consistently observe that the latter outperforms all other methods, including random sampling. Notably, uncertainty sampling, despite its success in conventional supervised learning scenarios, performs poorly in this context. Our extensive experimentation involving a diverse range of GPT and OPT models across 24 classification and multi-choice tasks, coupled with thorough analysis, unambiguously demonstrates that in-context example selection through AL prioritizes high-quality examples that exhibit low uncertainty and bear similarity to the test examples.</p>
        </div>
        
    </div>
</div></li>
<li><div class="row">
    <div class="col-sm-2 abbr">
        
        
        <abbr class="badge">EMNLP</abbr>
        
        

        
        <p>
            <i class="em em-trophy" aria-role="presentation" style="font-size: 0.5em;" aria-label="TROPHY"></i>
            <span  style="font-size: 0.8em;" >  ‚ú® Oral ‚ú®</span>
        </p>
        
<!--        -->
<!--        <p>-->
<!--            <i class="em em-trophy" aria-role="presentation" style="font-size: 0.7em;" aria-label="TROPHY"></i>-->
<!--            <span  style="font-size: 0.8em;" >  ‚ú® Oral ‚ú®</span>-->
<!--        </p>-->
<!--        -->

        
    </div>

    <div id="cal" class="col-sm-8">
        
        <div class="title">Active Learning by Acquiring Contrastive Examples</div>
        <div class="author">
            
            
            
            
            <em>Katerina Margatina</em>,
            
            
            
            
            
            
            
            
            Giorgos Vernikos,
            
            
            
            
            
            
            
            
            
            Lo√Øc Barrault,
            
            
            
            
            
            
            
            
            
            and Nikolaos Aletras
            
            
            
            
            
        </div>

        <div class="periodical">
            
            <em>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>
            
            
            2021
            
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            
            
            <a href="http://arxiv.org/abs/2109.03764" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
            
            
            <a href="https://aclanthology.org/2021.emnlp-main.51/" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-pager"></i> HTML</a>
            
            
            
            <a href="https://aclanthology.org/2021.emnlp-main.51.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
            
            
            
            
            
            <a href="https://twitter.com/katemargatina/status/1437393852227276801?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank">TL;DR</a>
            
            
            <a href="https://github.com/mourga/contrastive-active-learning" class="btn btn-sm z-depth-0" role="button" target="_blank"><i class="fas fa-code"></i> Code</a>
            
            
            
            <a href="https://drive.google.com/file/d/1JAdukTFb0ceAR0WRk9zEW2GqLiTG_p7H/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
            
            
            
            
            <a href="https://drive.google.com/file/d/1bWx9QPRTFjf49XLgCdV34w3w1SXETylv/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">
                <i class="far fa-file-powerpoint"></i>
                Slides</a>
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Common acquisition functions for active learning use either uncertainty or diversity sampling, aiming to select difficult and diverse data points from the pool of unlabeled data, respectively. In this work, leveraging the best of both worlds, we propose an acquisition function that opts for selecting \textitcontrastive examples, i.e. data points that are similar in the model feature space and yet the model outputs maximally different predictive likelihoods. We compare our approach, CAL (Contrastive Active Learning), with a diverse set of acquisition functions in four natural language understanding tasks and seven datasets. Our experiments show that CAL performs consistently better or equal than the best performing baseline across all tasks, on both in-domain and out-of-domain data. We also conduct an extensive ablation study of our method and we further analyze all actively acquired datasets showing that CAL achieves a better trade-off between uncertainty and diversity compared to other strategies.</p>
        </div>
        
    </div>
</div></li></ol>
</div>

    

    
    <div class="social">
      <a href="mailto:%6B%61%74%65%72%69%6E%61.%6D%61%72%67%61%74%69%6E%61@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=517t5gEAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
<a href="https://www.semanticscholar.org/author/Katerina-Margatina/82259306" target="_blank" title="Semantic Scholar"><i class="ai ai-semantic-scholar"></i></a>


<a href="https://github.com/mourga" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/katerina-margatina" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/katemargatina" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>










      <div class="contact-note"></div>
    </div>
    
  </article>

</div>
    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2026 Katerina  Margatina.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
